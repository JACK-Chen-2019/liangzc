---
title: 'Enhancing Continual Semantic Segmentation via Uncertainty and Class Balance Re-weighting'
date: 2024-3-18
permalink: /posts/2024/03/UCB/
tags:
  - Continual Semnatic Segmentation
---
[PDF](jackchen.cloud), [CODE](jackchen.cloud)

Abstract
======

Continual Semantic Segmentation (CSS) primarily aims to alleviate catastrophic forgetting. During the incremental stage, it is necessary to utilize the old model to generate pseudo-labels, as old classes are treated as background in the incremental stage. The quality of these pseudo-labels significantly influences the model's forgetting of the old categories. In this paper, we specifically address two previously overlooked problems: the impact of erroneous pseudo-labels on model forgetting and the confusion induced by class imbalance. We propose an \textbf{U}ncertainty and \textbf{C}lass \textbf{B}alance Re-weighting approach (\textbf{UCB}) that assigns higher weights to pixels with pseudo-labels exhibiting lower uncertainty and to categories with smaller proportions during the training process. Our proposed method is straightforward and can be applied to any method that uses pseudo-labels. Extensive experiments on the Pascal-VOC and ADE20K datasets illustrate the efficacy of our proposed approach in enhancing model performance.

------

连续语义分割（CSS）旨在缓解灾难性遗忘。由于在增量阶段中旧类别被标记背景类，在增量阶段，模型需要利用旧模型生成伪标签。这些伪标签的质量显著影响模型对旧类别的遗忘。本文重点解决了两个先前被忽视的问题：错误伪标签对模型遗忘的影响以及类别不平衡引起的类别混淆。我们提出了一种不确定性和类别平衡重新加权方法（UCB），在训练过程中为较低不确定性的像素和训练集中具有较小占比的类别分配更高的权重。我们提出的方法简单明了，并可应用于任何使用伪标签的方法。对Pascal-VOC和ADE20K数据集进行的大量实验表明我们提出的方法在提升模型性能方面的有效性。

Motivation
======

**The Relationship between Uncertainty and Accuracy.**
Figure (a) presents the statistical analysis of the relationship between prediction accuracy and uncertainty of PLOP in the 15-1 task. The uncertainty is categorized into 10 bins, and the accuracy (in blue) and pixel ratio (in green) of foreground categories are computed for each bin. Higher uncertainty leads to lower accuracy. Figure (b) visually illustrates the uncertainty, with the red regions representing higher uncertainty and a higher likelihood of prediction errors.

<img src='{{ site.url }}/images/uncertainty-visualize.jpg'>

Method
======

**Explanation of Our Method.**
Our approach aims to address the impact of erroneous labels and class imbalance by considering both prediction uncertainty and class balance factors to assign different weights to individual pixels. Specifically, we utilize entropy as a measure of uncertainty, allocating higher weights to pixels with lower entropy. We accurately assess the class proportion by calculating pixel ratios for different categories and assigning class balance weights based on their proportions. Finally, we multiply the calculated pixel-wise loss by the aforementioned weights to obtain the final loss.

<img src='{{ site.url }}/images/main.jpg'>

Results
======

We applied our method to PLOP,  SSUL and CoinSeg on the Pascal-VOC dataset. Results can be found in Table 1 and Table 2.

<img src='{{ site.url }}/images/table1.png'>
<img src='{{ site.url }}/images/table2.png'>
<img src='{{ site.url }}/images/results_step.png'>

Visualization
======

<img src='{{ site.url }}/images/visualization.jpg'>

Paper
======

Our paper will be released soon...
<embed src="{{ site.url }}/files/paper1.pdf" width="600" height="700" type='application/pdf'> 

Cite
======